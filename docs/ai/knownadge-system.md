# 机器学习知识体系

---

# 基本概念

下面这张图描述了在机器学习领域我们常见的一些概念及其相互之间的联系。

![image.png](https://images.zenhubusercontent.com/5b83aeb622e474383b984d11/0f2dcb98-a195-4f4b-a945-cff51890535d)

## 人工智能（AI，Artificial Intelligence）

人工智能是计算机科学的一个分支，它企图了解智能的实质，并生产出一种新的能以人类智能相似的方式做出反应的智能机器，该领域的研究包括机器人、语言识别、图像识别、自然语言处理和专家系统等很多分支。

## 机器学习（ML，Machine Learning）

机器学习是人工智能的核心，专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。

常见的机器学习方式有三种

- 监督学习，输入数据中有导师信号，以概率函数、代数函数或人工神经网络为基函数模型，采用迭代计算方法，学习结果为函数。
- 无监督学习，输入数据中无导师信号，采用聚类方法，学习结果为类别。常常被用于数据挖掘，用于在大量无标签数据中发现些什么。无监督主要有三种：聚类、离散点检测和降维。
- 强化学习，以环境反馈（奖/惩信号）作为输入，以统计和动态规划技术为指导的一种学习方法。机器被放置在一个特定环境中，在这个环境里机器可以持续性地进行自我训练，而环境会给出或正或负的反馈。机器会从以往的行动经验中得到提升并最终找到最好的知识内容来帮助它做出最有效的行为决策。例如 AlphaGo。


常见的机器学习算法有以下这些

- 回归算法，Linear Regression 线性回归以及 Logistic Regression 逻辑回归。一般说的 LR 模型指的是逻辑回归模型，逻辑回归只是对对线性回归的计算结果加上了一个Sigmoid函数，将数值结果转化为了0到1之间的概率
- 聚类算法，无监督算法中最典型的代表就是聚类算法。聚类算法中最典型的代表就是 K-Means 算法。
- 决策树算法（Decision Tree Model）
- 朴素贝叶斯算法（Naive Bayesian Model，NBM）
- 支持向量机算法（Support Vector Machine，SVM）
- 随机森林算法（Random Forest，RF）
- 人工神经网络算法（ANN）
- Boosting与Bagging算法
- 深度学习算法（Deep Learning，DL）
- 推荐算法，一类是基于物品内容的推荐，是将与用户购买的内容近似的物品推荐给用户；另一类是基于用户相似度的推荐，则是将与目标用户兴趣相同的其他用户购买的东西推荐给目标用户。两类推荐都有各自的优缺点，在一般的电商应用中，一般是两类混合使用。推荐算法中最有名的算法就是协同过滤算法。

常见的一些概念基本都和机器学习有深入的联系，例如模式识别=机器学习（前者来自工业界，后者则源自计算机学科）；数据挖掘=机器学习+数据库；统计学习≈机器学习（因为机器学习中的大多数方法来自统计学，前者偏向于数学中的统计模型研究，后者则偏重于计算机中的应用）；计算机视觉=图像处理+机器学习；语音识别=语音处理+机器学习；自然语言处理=文本处理+机器学习等等。


## 深度学习（DL，Deep Learning）

2006年，Geoffrey Hinton在科学杂志《Science》上发表了一篇文章，论证了两个观点：

1. 多隐层的神经网络具有优异的特征学习能力，学习得到的特征对数据有更本质的刻画，从而有利于可视化或分类；
2. 深度神经网络在训练上的难度，可以通过“逐层初始化” 来有效克服。

通过这样的发现，不仅解决了神经网络在计算上的难度，同时也说明了深层神经网络在学习上的优异性。从此，神经网络重新成为了机器学习界中的主流强大学习技术。同时，具有多个隐藏层的神经网络被称为深度神经网络，基于深度神经网络的学习研究称之为深度学习。

深度学习是机器学习的一种算法，它的概念源于人工神经网络的研究，含多个隐藏层的多层感知器（MLP，Multilayer Perceptron）就是一种深度学习结构。深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。研究深度学习的动机在于建立模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据，例如图像，声音和文本等。

就具体研究内容而言，主要涉及三类方法：基于卷积运算的神经网络系统，即卷积神经网络(CNN)；基于多层神经元的自编码神经网络，包括自编码( Auto encoder)以及近年来受到广泛关注的稀疏编码两类( Sparse Coding)；以多层自编码神经网络的方式进行预训练，进而结合鉴别信息进一步优化神经网络权值的深度置信网络(DBN)。

深度学习通过多层处理，逐渐将初始的“低层”特征表示转化为“高层”特征表示后，用“简单模型”即可完成复杂的分类等学习任务。由此可将深度学习理解为进行“特征学习”（feature learning）或“表示学习”（representation learning）。所以其本质是通过机器学习技术自身来产生好特征。从另一个角度讲深度学习明确了特征学习的重要性。也就是说，通过逐层特征变换，将样本在原空间的特征表示变换到一个新特征空间，从而使分类或预测更容易。与人工规则构造特征的方法相比，利用大数据来学习特征，更能够刻画数据丰富的内在信息。

另一方面深度学习强调了模型结构的深度，通常有5层、6层，甚至10多层的隐层节点。通过设计建立适量的神经元计算节点和多层运算层次结构，选择合适的输人层和输出层，通过网络的学习和调优，建立起从输入到输出的函数关系，虽然不能100%找到输入与输出的函数关系，但是可以尽可能的逼近现实的关联关系。使用训练成功的网络模型，就可以实现我们对复杂事务处理的自动化要求。


## 神经网络（全称人工神经网络，ANNs，Artificial Neural Networks）

人工神经网络是由大量处理单元互联组成的非线性、自适应信息处理系统。它是在现代神经科学研究成果的基础上提出的，试图通过模拟大脑神经网络处理、记忆信息的方式进行信息处理。人工神经网络具有四个基本特征：非线性、非局限性、非常定性及非凸性。根据连接的拓扑结构，神经网络模型可以分为：前向网络（有向无环图，实现信号从输入空间到输出空间的变换）及反馈网略（网络内神经元间有反馈，可以用一个无向的完备图表示）。

神经网络是一种运算模型，由大量的节点（或称神经元）之间相互联接构成。每个节点代表一种特定的输出函数，称为激励函数（activation function）。每两个节点间的连接都代表一个对于通过该连接信号的加权值，称之为权重，这相当于人工神经网络的记忆。网络的输出则依网络的连接方式，权重值和激励函数的不同而不同。而网络自身通常都是对自然界某种算法或者函数的逼近，也可能是对一种逻辑策略的表达。

人工神经网络的特点和优越性，主要表现在三个方面：自学习功能、联想存储功能以及高速寻找优化解的能力。最近十多年来，人工神经网络的研究工作不断深入，已经取得了很大的进展，其在模式识别、智能机器人、自动控制、预测估计、生物、医学、经济等领域已成功地解决了许多现代计算机难以解决的实际问题，表现出了良好的智能特性。